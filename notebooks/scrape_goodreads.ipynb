{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving books from: https://www.goodreads.com/list/show/1.Best_Books_Ever\n",
      "Fetching page 1... (0 books collected so far)\n",
      "List title: Best Books Ever\n",
      "Found 100 books on this page.\n",
      "Waiting 3.03 seconds before next request...\n",
      "Fetching page 2... (100 books collected so far)\n",
      "List title: Best Books Ever\n",
      "Found 100 books on this page.\n",
      "Waiting 3.69 seconds before next request...\n",
      "Fetching page 3... (200 books collected so far)\n",
      "List title: Best Books Ever\n",
      "Found 100 books on this page.\n",
      "Waiting 3.07 seconds before next request...\n",
      "Fetching page 4... (300 books collected so far)\n",
      "List title: Best Books Ever\n",
      "Found 100 books on this page.\n",
      "Waiting 2.34 seconds before next request...\n",
      "Fetching page 5... (400 books collected so far)\n",
      "List title: Best Books Ever\n",
      "Found 100 books on this page.\n",
      "Waiting 4.03 seconds before next request...\n",
      "Fetching page 6... (500 books collected so far)\n",
      "List title: Best Books Ever\n",
      "Found 100 books on this page.\n",
      "Waiting 4.38 seconds before next request...\n",
      "Fetching page 7... (600 books collected so far)\n",
      "List title: Best Books Ever\n",
      "Found 100 books on this page.\n",
      "Waiting 2.54 seconds before next request...\n",
      "Fetching page 8... (700 books collected so far)\n",
      "List title: Best Books Ever\n",
      "Found 100 books on this page.\n",
      "Waiting 4.22 seconds before next request...\n",
      "Fetching page 9... (800 books collected so far)\n",
      "List title: Best Books Ever\n",
      "Found 100 books on this page.\n",
      "Waiting 4.62 seconds before next request...\n",
      "Fetching page 10... (900 books collected so far)\n",
      "List title: Best Books Ever\n",
      "Found 100 books on this page.\n",
      "Waiting 3.37 seconds before next request...\n",
      "Total books collected: 1000\n",
      "Books saved to goodreads_best_books_ever.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_genre</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>author_url</th>\n",
       "      <th>author_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>cover_url</th>\n",
       "      <th>id</th>\n",
       "      <th>url_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Books Ever</td>\n",
       "      <td>The Hunger Games (The Hunger Games #1)</td>\n",
       "      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>https://www.goodreads.com/author/show/153394.S...</td>\n",
       "      <td>153394</td>\n",
       "      <td>4.34</td>\n",
       "      <td>9317126</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2767052</td>\n",
       "      <td>[2767052 the hunger games]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Books Ever</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Har...</td>\n",
       "      <td>https://www.goodreads.com/book/show/2.Harry_Po...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>https://www.goodreads.com/author/show/1077326....</td>\n",
       "      <td>1077326</td>\n",
       "      <td>4.50</td>\n",
       "      <td>3616355</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best Books Ever</td>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>https://www.goodreads.com/book/show/1885.Pride...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>https://www.goodreads.com/author/show/1265.Jan...</td>\n",
       "      <td>1265</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4517211</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>1885</td>\n",
       "      <td>[1885, Pride_and_prejudice]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Books Ever</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>https://www.goodreads.com/author/show/1825.Har...</td>\n",
       "      <td>1825</td>\n",
       "      <td>4.26</td>\n",
       "      <td>6563388</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>2657</td>\n",
       "      <td>[2657, To_kill_a_mockingbird]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best Books Ever</td>\n",
       "      <td>The Book Thief</td>\n",
       "      <td>https://www.goodreads.com/book/show/19063.The_...</td>\n",
       "      <td>Markus Zusak</td>\n",
       "      <td>https://www.goodreads.com/author/show/11466.Ma...</td>\n",
       "      <td>11466</td>\n",
       "      <td>4.39</td>\n",
       "      <td>2745941</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>19063</td>\n",
       "      <td>[19063, The_book_thief]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Best Books Ever</td>\n",
       "      <td>Twilight (The Twilight Saga, #1)</td>\n",
       "      <td>https://www.goodreads.com/book/show/41865.Twil...</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>https://www.goodreads.com/author/show/941441.S...</td>\n",
       "      <td>941441</td>\n",
       "      <td>3.66</td>\n",
       "      <td>7000710</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>41865</td>\n",
       "      <td>[41865, Twilight]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Best Books Ever</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>https://www.goodreads.com/book/show/170448.Ani...</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>https://www.goodreads.com/author/show/3706.Geo...</td>\n",
       "      <td>3706</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4227067</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>170448</td>\n",
       "      <td>[170448, Animal_farm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Best Books Ever</td>\n",
       "      <td>J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...</td>\n",
       "      <td>https://www.goodreads.com/book/show/30.J_R_R_T...</td>\n",
       "      <td>J.R.R. Tolkien</td>\n",
       "      <td>https://www.goodreads.com/author/show/656983.J...</td>\n",
       "      <td>656983</td>\n",
       "      <td>4.61</td>\n",
       "      <td>139663</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Best Books Ever</td>\n",
       "      <td>The Chronicles of Narnia (The Chronicles of Na...</td>\n",
       "      <td>https://www.goodreads.com/book/show/11127.The_...</td>\n",
       "      <td>C.S. Lewis</td>\n",
       "      <td>https://www.goodreads.com/author/show/1069006....</td>\n",
       "      <td>1069006</td>\n",
       "      <td>4.28</td>\n",
       "      <td>685618</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>11127</td>\n",
       "      <td>[11127, The_chronicles_of_narnia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Best Books Ever</td>\n",
       "      <td>The Fault in Our Stars</td>\n",
       "      <td>https://www.goodreads.com/book/show/11870085-t...</td>\n",
       "      <td>John Green</td>\n",
       "      <td>https://www.goodreads.com/author/show/1406384....</td>\n",
       "      <td>1406384</td>\n",
       "      <td>4.13</td>\n",
       "      <td>5480099</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>11870085</td>\n",
       "      <td>[11870085 the fault in our stars]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        list_genre                                              title  \\\n",
       "0  Best Books Ever             The Hunger Games (The Hunger Games #1)   \n",
       "1  Best Books Ever  Harry Potter and the Order of the Phoenix (Har...   \n",
       "2  Best Books Ever                                Pride and Prejudice   \n",
       "3  Best Books Ever                              To Kill a Mockingbird   \n",
       "4  Best Books Ever                                     The Book Thief   \n",
       "5  Best Books Ever                   Twilight (The Twilight Saga, #1)   \n",
       "6  Best Books Ever                                        Animal Farm   \n",
       "7  Best Books Ever  J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...   \n",
       "8  Best Books Ever  The Chronicles of Narnia (The Chronicles of Na...   \n",
       "9  Best Books Ever                             The Fault in Our Stars   \n",
       "\n",
       "                                                 url           author  \\\n",
       "0  https://www.goodreads.com/book/show/2767052-th...  Suzanne Collins   \n",
       "1  https://www.goodreads.com/book/show/2.Harry_Po...     J.K. Rowling   \n",
       "2  https://www.goodreads.com/book/show/1885.Pride...      Jane Austen   \n",
       "3  https://www.goodreads.com/book/show/2657.To_Ki...       Harper Lee   \n",
       "4  https://www.goodreads.com/book/show/19063.The_...     Markus Zusak   \n",
       "5  https://www.goodreads.com/book/show/41865.Twil...  Stephenie Meyer   \n",
       "6  https://www.goodreads.com/book/show/170448.Ani...    George Orwell   \n",
       "7  https://www.goodreads.com/book/show/30.J_R_R_T...   J.R.R. Tolkien   \n",
       "8  https://www.goodreads.com/book/show/11127.The_...       C.S. Lewis   \n",
       "9  https://www.goodreads.com/book/show/11870085-t...       John Green   \n",
       "\n",
       "                                          author_url author_id  rating  \\\n",
       "0  https://www.goodreads.com/author/show/153394.S...    153394    4.34   \n",
       "1  https://www.goodreads.com/author/show/1077326....   1077326    4.50   \n",
       "2  https://www.goodreads.com/author/show/1265.Jan...      1265    4.29   \n",
       "3  https://www.goodreads.com/author/show/1825.Har...      1825    4.26   \n",
       "4  https://www.goodreads.com/author/show/11466.Ma...     11466    4.39   \n",
       "5  https://www.goodreads.com/author/show/941441.S...    941441    3.66   \n",
       "6  https://www.goodreads.com/author/show/3706.Geo...      3706    4.00   \n",
       "7  https://www.goodreads.com/author/show/656983.J...    656983    4.61   \n",
       "8  https://www.goodreads.com/author/show/1069006....   1069006    4.28   \n",
       "9  https://www.goodreads.com/author/show/1406384....   1406384    4.13   \n",
       "\n",
       "   rating_count                                          cover_url        id  \\\n",
       "0       9317126  https://i.gr-assets.com/images/S/compressed.ph...   2767052   \n",
       "1       3616355  https://i.gr-assets.com/images/S/compressed.ph...         2   \n",
       "2       4517211  https://i.gr-assets.com/images/S/compressed.ph...      1885   \n",
       "3       6563388  https://i.gr-assets.com/images/S/compressed.ph...      2657   \n",
       "4       2745941  https://i.gr-assets.com/images/S/compressed.ph...     19063   \n",
       "5       7000710  https://i.gr-assets.com/images/S/compressed.ph...     41865   \n",
       "6       4227067  https://i.gr-assets.com/images/S/compressed.ph...    170448   \n",
       "7        139663  https://i.gr-assets.com/images/S/compressed.ph...        30   \n",
       "8        685618  https://i.gr-assets.com/images/S/compressed.ph...     11127   \n",
       "9       5480099  https://i.gr-assets.com/images/S/compressed.ph...  11870085   \n",
       "\n",
       "                          url_genres  \n",
       "0         [2767052 the hunger games]  \n",
       "1                                NaN  \n",
       "2        [1885, Pride_and_prejudice]  \n",
       "3      [2657, To_kill_a_mockingbird]  \n",
       "4            [19063, The_book_thief]  \n",
       "5                  [41865, Twilight]  \n",
       "6              [170448, Animal_farm]  \n",
       "7                                NaN  \n",
       "8  [11127, The_chronicles_of_narnia]  \n",
       "9  [11870085 the fault in our stars]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Configure user agent\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "}\n",
    "\n",
    "def get_books_from_list(list_url, limit=500, delay_range=(2, 5)):\n",
    "   \n",
    "    books = []\n",
    "    page = 1\n",
    "    failures = 0\n",
    "    max_failures = 5\n",
    "    \n",
    "    print(f\"Retrieving books from: {list_url}\")\n",
    "    \n",
    "    while len(books) < limit:\n",
    "        try:\n",
    "            # Construct URL for pagination\n",
    "            if page == 1:\n",
    "                page_url = list_url\n",
    "            else:\n",
    "                page_url = f\"{list_url}?page={page}\"\n",
    "                \n",
    "            print(f\"Fetching page {page}... ({len(books)} books collected so far)\")\n",
    "            \n",
    "            response = requests.get(page_url, headers=headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Find all book entries on the page\n",
    "            book_elements = soup.select('tr[itemtype=\"http://schema.org/Book\"]')\n",
    "            \n",
    "            if not book_elements:\n",
    "                book_elements = soup.select('tr.bookalike')\n",
    "            \n",
    "            if not book_elements:\n",
    "                book_elements = soup.select('div.bookTitle')\n",
    "            \n",
    "            if not book_elements:\n",
    "                print(\"No more books found on this page. Trying alternative selectors...\")\n",
    "                \n",
    "                # Alternative selectors for newer Goodreads layout\n",
    "                book_elements = soup.select('div.BookListItem, article.BookListItem')\n",
    "                \n",
    "                if not book_elements:\n",
    "                    print(\"No books found with alternative selectors either.\")\n",
    "                    book_elements = soup.select('div[class*=\"Book\"]')\n",
    "                    \n",
    "                    if not book_elements:\n",
    "                        print(\"No books found on this page. Moving to the next page.\")\n",
    "                        page += 1\n",
    "                        if page > 10:  # Limit to 10 pages if we're not finding books\n",
    "                            print(\"Reached 10 pages without finding books. Stopping.\")\n",
    "                            break\n",
    "                        continue\n",
    "            \n",
    "            print(f\"Found {len(book_elements)} books on this page.\")\n",
    "            \n",
    "            for book_element in book_elements:\n",
    "                if len(books) >= limit:\n",
    "                    break\n",
    "                \n",
    "                book_data = {}\n",
    "                \n",
    "                # Parse book data based on the element type\n",
    "                if book_element.name == 'tr':\n",
    "                    # Old Goodreads layout\n",
    "                    \n",
    "                    # Get title and URL\n",
    "                    title_element = book_element.select_one('a.bookTitle')\n",
    "                    if title_element:\n",
    "                        book_data['title'] = title_element.text.strip()\n",
    "                        book_data['url'] = title_element['href']\n",
    "                        if not book_data['url'].startswith('http'):\n",
    "                            book_data['url'] = f\"https://www.goodreads.com{book_data['url']}\"\n",
    "                    \n",
    "                    # Get author\n",
    "                    author_element = book_element.select_one('a.authorName')\n",
    "                    if author_element:\n",
    "                        book_data['author'] = author_element.text.strip()\n",
    "                    \n",
    "                    # Get rating\n",
    "                    rating_element = book_element.select_one('span.minirating')\n",
    "                    if rating_element:\n",
    "                        rating_text = rating_element.text.strip()\n",
    "                        rating_match = re.search(r'(\\d+\\.\\d+)', rating_text)\n",
    "                        if rating_match:\n",
    "                            book_data['rating'] = float(rating_match.group(1))\n",
    "                        \n",
    "                        # Get number of ratings\n",
    "                        rating_count_match = re.search(r'(\\d+(?:,\\d+)*) ratings', rating_text)\n",
    "                        if rating_count_match:\n",
    "                            book_data['rating_count'] = rating_count_match.group(1).replace(',', '')\n",
    "                    \n",
    "                elif book_element.name == 'div' or book_element.name == 'article':\n",
    "                    # New Goodreads layout\n",
    "                    \n",
    "                    # Get title and URL\n",
    "                    title_element = book_element.select_one('a[href*=\"/book/show/\"], h3 a, .BookTitle a')\n",
    "                    if title_element:\n",
    "                        book_data['title'] = title_element.text.strip()\n",
    "                        book_data['url'] = title_element['href']\n",
    "                        if not book_data['url'].startswith('http'):\n",
    "                            book_data['url'] = f\"https://www.goodreads.com{book_data['url']}\"\n",
    "                    \n",
    "                    # Get author\n",
    "                    author_element = book_element.select_one('a.AuthorName, span.AuthorName a, a[href*=\"/author/show/\"]')\n",
    "                    if author_element:\n",
    "                        book_data['author'] = author_element.text.strip()\n",
    "                    \n",
    "                    # Get rating\n",
    "                    rating_element = book_element.select_one('span.RatingStars__RatingsValue, span[class*=\"RatingValue\"]')\n",
    "                    if rating_element:\n",
    "                        rating_text = rating_element.text.strip()\n",
    "                        try:\n",
    "                            book_data['rating'] = float(rating_text)\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                # Only add if we have at least a title\n",
    "                if 'title' in book_data:\n",
    "                    # Extract book ID from URL if available\n",
    "                    if 'url' in book_data:\n",
    "                        id_match = re.search(r'/show/(\\d+)', book_data['url'])\n",
    "                        if id_match:\n",
    "                            book_data['id'] = id_match.group(1)\n",
    "                    \n",
    "                    books.append(book_data)\n",
    "            \n",
    "            # Reset failure counter on success\n",
    "            failures = 0\n",
    "            \n",
    "            # Check if there's a next page\n",
    "            next_link = soup.select_one('a.next_page')\n",
    "            if not next_link:\n",
    "                next_link = soup.select_one('a[rel=\"next\"]')\n",
    "                \n",
    "            if not next_link:\n",
    "                print(\"No more pages available.\")\n",
    "                break\n",
    "                \n",
    "            # Move to the next page\n",
    "            page += 1\n",
    "            \n",
    "            # Respect rate limits with a random delay\n",
    "            delay = random.uniform(delay_range[0], delay_range[1])\n",
    "            print(f\"Waiting {delay:.2f} seconds before next request...\")\n",
    "            time.sleep(delay)\n",
    "            \n",
    "        except Exception as e:\n",
    "            failures += 1\n",
    "            print(f\"Error on page {page}: {type(e).__name__}: {str(e)}\")\n",
    "            print(f\"Attempt {failures} of {max_failures}\")\n",
    "            \n",
    "            if failures >= max_failures:\n",
    "                print(\"Too many consecutive failures. Stopping.\")\n",
    "                break\n",
    "                \n",
    "            # Increase delay after failure\n",
    "            delay = random.uniform(delay_range[0] * 2, delay_range[1] * 2)\n",
    "            print(f\"Waiting {delay:.2f} seconds before retrying...\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    print(f\"Total books collected: {len(books)}\")\n",
    "    return books[:limit]  # Ensure we don't exceed the limit\n",
    "\n",
    "\n",
    "def get_books_from_search(query, limit=500, delay_range=(2, 5)):\n",
    "    \"\"\"\n",
    "    Get books from a Goodreads search query\n",
    "    \n",
    "    Parameters:\n",
    "    query (str): Search query\n",
    "    limit (int): Maximum number of books to retrieve\n",
    "    delay_range (tuple): Range of seconds to wait between pagination requests\n",
    "    \n",
    "    Returns:\n",
    "    list: List of book details\n",
    "    \"\"\"\n",
    "    # Format the search URL\n",
    "    search_url = f\"https://www.goodreads.com/search?q={query.replace(' ', '+')}&search_type=books\"\n",
    "    \n",
    "    return get_books_from_list(search_url, limit, delay_range)\n",
    "\n",
    "def get_books_from_genre(genre, limit=500, delay_range=(2, 5)):\n",
    "   \n",
    "    genre_url = f\"https://www.goodreads.com/genres/{genre.lower().replace(' ', '-')}\"\n",
    "    \n",
    "    books = []\n",
    "    failures = 0\n",
    "    max_failures = 5\n",
    "    \n",
    "    try:\n",
    "        print(f\"Fetching genre page: {genre_url}\")\n",
    "        \n",
    "        response = requests.get(genre_url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find popular books on the genre page\n",
    "        book_elements = soup.select('div.leftContainer div.bookBox')\n",
    "        \n",
    "        print(f\"Found {len(book_elements)} books on genre page.\")\n",
    "        \n",
    "        for book_element in book_elements:\n",
    "            if len(books) >= limit:\n",
    "                break\n",
    "                \n",
    "            book_data = {}\n",
    "            \n",
    "            # Get title and URL\n",
    "            title_element = book_element.select_one('a.bookTitle')\n",
    "            if title_element:\n",
    "                book_data['title'] = title_element.text.strip()\n",
    "                book_data['url'] = title_element['href']\n",
    "                if not book_data['url'].startswith('http'):\n",
    "                    book_data['url'] = f\"https://www.goodreads.com{book_data['url']}\"\n",
    "            \n",
    "            # Get author\n",
    "            author_element = book_element.select_one('a.authorName')\n",
    "            if author_element:\n",
    "                book_data['author'] = author_element.text.strip()\n",
    "                # Get author URL\n",
    "                book_data['author_url'] = author_element['href']\n",
    "                if not book_data['author_url'].startswith('http'):\n",
    "                    book_data['author_url'] = f\"https://www.goodreads.com{book_data['author_url']}\"\n",
    "                # Extract author ID\n",
    "                author_id_match = re.search(r'/author/show/(\\d+)', book_data['author_url'])\n",
    "                if author_id_match:\n",
    "                    book_data['author_id'] = author_id_match.group(1)\n",
    "            \n",
    "            # Get rating\n",
    "            rating_element = book_element.select_one('span.minirating')\n",
    "            if rating_element:\n",
    "                rating_text = rating_element.text.strip()\n",
    "                # Extract average rating\n",
    "                rating_match = re.search(r'(\\d+\\.\\d+)', rating_text)\n",
    "                if rating_match:\n",
    "                    book_data['rating'] = float(rating_match.group(1))\n",
    "                \n",
    "                # Extract number of ratings\n",
    "                rating_count_match = re.search(r'(\\d+(?:,\\d+)*) ratings', rating_text)\n",
    "                if rating_count_match:\n",
    "                    book_data['rating_count'] = int(rating_count_match.group(1).replace(',', ''))\n",
    "            \n",
    "            # Get book cover image\n",
    "            cover_element = book_element.select_one('img.bookCover')\n",
    "            if cover_element:\n",
    "                book_data['cover_url'] = cover_element['src']\n",
    "                # Sometimes the image is lazy-loaded\n",
    "                if not book_data['cover_url'].startswith('http') or book_data['cover_url'].endswith('nophoto'):\n",
    "                    data_url = cover_element.get('data-lazy', '')\n",
    "                    if data_url and data_url.startswith('http'):\n",
    "                        book_data['cover_url'] = data_url\n",
    "            \n",
    "            # Get description snippet if available\n",
    "            description_element = book_element.select_one('div.description, span.smallText')\n",
    "            if description_element:\n",
    "                book_data['description_snippet'] = description_element.text.strip()\n",
    "            \n",
    "            # Get publication year if available\n",
    "            pub_year_element = book_element.select_one('div.uitext, div.smallText')\n",
    "            if pub_year_element:\n",
    "                pub_text = pub_year_element.text.strip()\n",
    "                pub_year_match = re.search(r'published\\s+(\\d{4})', pub_text, re.IGNORECASE)\n",
    "                if pub_year_match:\n",
    "                    book_data['publication_year'] = int(pub_year_match.group(1))\n",
    "            \n",
    "            # Only add if we have at least a title\n",
    "            if 'title' in book_data:\n",
    "                # Extract book ID from URL if available\n",
    "                if 'url' in book_data:\n",
    "                    id_match = re.search(r'/show/(\\d+)', book_data['url'])\n",
    "                    if id_match:\n",
    "                        book_data['id'] = id_match.group(1)\n",
    "                \n",
    "                # Extract featured shelves/genres from the page if available\n",
    "                try:\n",
    "                    shelves_div = book_element.select_one('div.elementList div.left')\n",
    "                    if shelves_div:\n",
    "                        shelf_text = shelves_div.text.strip()\n",
    "                        shelves_match = re.search(r'genre:(.*?)(?:$|shelved as)', shelf_text, re.IGNORECASE)\n",
    "                        if shelves_match:\n",
    "                            shelf_list = [s.strip() for s in shelves_match.group(1).split(',')]\n",
    "                            book_data['shelves'] = shelf_list\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                books.append(book_data)\n",
    "        \n",
    "        # If we need more books, check for \"most read this week\" or \"popular\" sections\n",
    "        if len(books) < limit:\n",
    "            more_book_elements = soup.select('div.readable div.left a.bookTitle, div.readable div.bookTitleContainer')\n",
    "            \n",
    "            if more_book_elements:\n",
    "                print(f\"Found {len(more_book_elements)} additional books in 'most read' section.\")\n",
    "                \n",
    "                for book_element in more_book_elements:\n",
    "                    if len(books) >= limit:\n",
    "                        break\n",
    "                    \n",
    "                    book_data = {}\n",
    "                    \n",
    "                    # If it's a direct title link\n",
    "                    if 'bookTitle' in book_element.get('class', []):\n",
    "                        book_data['title'] = book_element.text.strip()\n",
    "                        book_data['url'] = book_element['href']\n",
    "                        if not book_data['url'].startswith('http'):\n",
    "                            book_data['url'] = f\"https://www.goodreads.com{book_data['url']}\"\n",
    "                            \n",
    "                        # Try to find the author and rating in the parent container\n",
    "                        parent = book_element.find_parent('div')\n",
    "                        if parent:\n",
    "                            author_element = parent.select_one('a.authorName')\n",
    "                            if author_element:\n",
    "                                book_data['author'] = author_element.text.strip()\n",
    "                            \n",
    "                            rating_element = parent.select_one('span.minirating, span.greyText')\n",
    "                            if rating_element:\n",
    "                                rating_text = rating_element.text.strip()\n",
    "                                rating_match = re.search(r'(\\d+\\.\\d+)', rating_text)\n",
    "                                if rating_match:\n",
    "                                    book_data['rating'] = float(rating_match.group(1))\n",
    "                    \n",
    "                    # If it's a container, parse its contents\n",
    "                    elif 'bookTitleContainer' in book_element.get('class', []):\n",
    "                        title_element = book_element.select_one('a.bookTitle')\n",
    "                        if title_element:\n",
    "                            book_data['title'] = title_element.text.strip()\n",
    "                            book_data['url'] = title_element['href']\n",
    "                            if not book_data['url'].startswith('http'):\n",
    "                                book_data['url'] = f\"https://www.goodreads.com{book_data['url']}\"\n",
    "                        \n",
    "                        author_element = book_element.select_one('a.authorName')\n",
    "                        if author_element:\n",
    "                            book_data['author'] = author_element.text.strip()\n",
    "                        \n",
    "                        rating_element = book_element.select_one('span.minirating, span.greyText')\n",
    "                        if rating_element:\n",
    "                            rating_text = rating_element.text.strip()\n",
    "                            rating_match = re.search(r'(\\d+\\.\\d+)', rating_text)\n",
    "                            if rating_match:\n",
    "                                book_data['rating'] = float(rating_match.group(1))\n",
    "                    \n",
    "                    # Extract book ID from URL\n",
    "                    if 'url' in book_data:\n",
    "                        id_match = re.search(r'/show/(\\d+)', book_data['url'])\n",
    "                        if id_match:\n",
    "                            book_data['id'] = id_match.group(1)\n",
    "                    \n",
    "                    # Only add if we have at least a title and it's not a duplicate\n",
    "                    if 'title' in book_data and 'id' in book_data:\n",
    "                        # Check for duplicates by ID\n",
    "                        if not any(b.get('id') == book_data['id'] for b in books):\n",
    "                            books.append(book_data)\n",
    "        \n",
    "        # If we still need more books, look for related lists\n",
    "        if len(books) < limit:\n",
    "            list_elements = soup.select('div.listItem a.listTitle, div.list a.listTitle')\n",
    "            \n",
    "            if list_elements:\n",
    "                print(f\"Found {len(list_elements)} related lists. Fetching more books...\")\n",
    "                \n",
    "                # Get a random list to fetch more books\n",
    "                random_list = random.choice(list_elements)\n",
    "                list_url = random_list['href']\n",
    "                if not list_url.startswith('http'):\n",
    "                    list_url = f\"https://www.goodreads.com{list_url}\"\n",
    "                \n",
    "                # Get books from the list\n",
    "                list_books = get_books_from_list(list_url, limit=limit-len(books), delay_range=delay_range)\n",
    "                \n",
    "                # Add only non-duplicate books from the list\n",
    "                for list_book in list_books:\n",
    "                    if len(books) >= limit:\n",
    "                        break\n",
    "                        \n",
    "                    if 'id' in list_book:\n",
    "                        # Check for duplicates by ID\n",
    "                        if not any(b.get('id') == list_book['id'] for b in books):\n",
    "                            books.append(list_book)\n",
    "                    else:\n",
    "                        # If no ID, check for duplicates by title and author\n",
    "                        if not any(b.get('title') == list_book.get('title') and b.get('author') == list_book.get('author') for b in books):\n",
    "                            books.append(list_book)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching genre page: {type(e).__name__}: {str(e)}\")\n",
    "        print(f\"Attempt {failures + 1} of {max_failures}\")\n",
    "        \n",
    "        failures += 1\n",
    "        if failures < max_failures:\n",
    "            delay = random.uniform(delay_range[0] * 2, delay_range[1] * 2)\n",
    "            print(f\"Waiting {delay:.2f} seconds before retrying...\")\n",
    "            time.sleep(delay)\n",
    "            # Recursively try again with remaining limit\n",
    "            additional_books = get_books_from_genre(genre, limit=limit-len(books), delay_range=delay_range)\n",
    "            books.extend(additional_books)\n",
    "    \n",
    "    print(f\"Total books collected from genre: {len(books)}\")\n",
    "    return books[:limit]  # Ensure we don't exceed the limit\n",
    "\n",
    "def save_to_csv(books_data, filename=\"goodreads_books.csv\"):\n",
    "    \"\"\"Save the books data to a CSV file\"\"\"\n",
    "    df = pd.DataFrame(books_data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Books saved to {filename}\")\n",
    "    return df\n",
    "\n",
    "bestsellers_url = \"https://www.goodreads.com/list/show/1.Best_Books_Ever\"\n",
    "bestsellers = get_books_from_list(bestsellers_url, limit=1000)\n",
    "bestsellers_df = save_to_csv(bestsellers, \"goodreads_best_books_ever.csv\")\n",
    "display(bestsellers_df.head(10))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
